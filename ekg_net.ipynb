{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, severe_ds, healthy_ds):\n",
    "        self.x = torch.concat([severe_ds[0],healthy_ds[0]])\n",
    "        self.y = torch.concat([severe_ds[1],healthy_ds[1]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "TRAIN_SET_PATH =  \"C:\\\\Users\\\\rbenjos\\\\Desktop\\\\ekg_proj\\\\train_ds.pt\"\n",
    "TEST_SET_PATH =  \"C:\\\\Users\\\\rbenjos\\\\Desktop\\\\ekg_proj\\\\test_ds.pt\"\n",
    "\n",
    "train_set = torch.load(TRAIN_SET_PATH)\n",
    "test_set = torch.load(TEST_SET_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,batch_size=4,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=4,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "## Constants\n",
    "INPUT_CH = 12\n",
    "INPUT_DIM = 1250\n",
    "OUTPUT_DIM = 2\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    # a simple 1d convolutional neural network\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self.conv1 = nn.Conv1d(INPUT_CH,INPUT_CH+2,5)\n",
    "        self.conv2 = nn.Conv1d(INPUT_CH+2,INPUT_CH+4,5)\n",
    "        self.conv3 = nn.Conv1d(INPUT_CH+4,INPUT_CH+6,5)\n",
    "        self.conv4 = nn.Conv1d(INPUT_CH+6,INPUT_CH+8,5)\n",
    "        self.conv5 = nn.Conv1d(INPUT_CH+8,INPUT_CH+10,5)\n",
    "        self.conv6 = nn.Conv1d(INPUT_CH+10,INPUT_CH+12,5)\n",
    "\n",
    "        self.conv_layers = [self.conv1,self.conv2,self.conv3,\n",
    "                            self.conv4,self.conv5,self.conv6]\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear((INPUT_CH+12)*15,180)\n",
    "        self.fc2 = nn.Linear(180,60)\n",
    "        self.fc3 = nn.Linear(60,20)\n",
    "        self.fc4 = nn.Linear(20,2)\n",
    "\n",
    "        # 1d max pooling\n",
    "        self.maxpool = nn.MaxPool1d(2,stride=2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # convolutions\n",
    "        for conv in self.conv_layers:\n",
    "            x = F.relu(conv(x))\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "\n",
    "        x = torch.flatten(x,1)\n",
    "        # fully connected until 2 classes\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def train_test_epoch(net,criterion,optimizer,epoch):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            # print and log every 10\n",
    "            print(f'train_loss is {running_loss/100} at epoch {epoch+1} ')\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            test_epoch(net,criterion)\n",
    "\n",
    "\n",
    "\n",
    "def test_epoch(net,criterion):\n",
    "    test_loss = 0.0\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "    print(f'test_loss is {test_loss}')\n",
    "\n",
    "\n",
    "def train_test_net(net,epochs):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.8)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_test_epoch(net,criterion,optimizer,epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss is 0.06444943904876708 at epoch 1 \n",
      "train_loss is 0.06211070954799652 at epoch 1 \n",
      "train_loss is 0.0595068633556366 at epoch 1 \n",
      "train_loss is 0.057001038789749145 at epoch 1 \n",
      "train_loss is 0.054627543091773985 at epoch 1 \n",
      "train_loss is 0.052387871742248536 at epoch 1 \n",
      "train_loss is 0.05026690036058426 at epoch 1 \n",
      "train_loss is 0.048248887956142426 at epoch 1 \n",
      "train_loss is 0.04633055627346039 at epoch 1 \n",
      "train_loss is 0.04450931340456009 at epoch 1 \n",
      "test_loss is 24.796063780784607\n",
      "train_loss is 0.042784683406353 at epoch 1 \n",
      "train_loss is 0.041144519448280334 at epoch 1 \n",
      "train_loss is 0.03958672553300858 at epoch 1 \n",
      "train_loss is 0.03810602605342865 at epoch 1 \n",
      "train_loss is 0.03876632690429688 at epoch 1 \n",
      "train_loss is 0.03547315448522568 at epoch 1 \n",
      "train_loss is 0.03421928107738495 at epoch 1 \n",
      "train_loss is 0.033009331524372104 at epoch 1 \n",
      "train_loss is 0.03434408843517303 at epoch 1 \n",
      "train_loss is 0.03595140814781189 at epoch 1 \n",
      "test_loss is 18.954312473535538\n",
      "train_loss is 0.029958842694759368 at epoch 1 \n",
      "train_loss is 0.03171321272850037 at epoch 1 \n",
      "train_loss is 0.030931875109672546 at epoch 1 \n",
      "train_loss is 0.027209576666355133 at epoch 1 \n",
      "train_loss is 0.026339347064495085 at epoch 1 \n",
      "train_loss is 0.025481263101100923 at epoch 1 \n",
      "train_loss is 0.02465553015470505 at epoch 1 \n",
      "train_loss is 0.02386509597301483 at epoch 1 \n",
      "train_loss is 0.02310377836227417 at epoch 1 \n",
      "train_loss is 0.02237549126148224 at epoch 1 \n",
      "test_loss is 15.511535555124283\n",
      "train_loss is 0.02524492338299751 at epoch 1 \n",
      "train_loss is 0.024736707955598833 at epoch 1 \n",
      "train_loss is 0.020506135672330856 at epoch 1 \n",
      "train_loss is 0.02369996443390846 at epoch 1 \n",
      "train_loss is 0.01938862383365631 at epoch 1 \n",
      "train_loss is 0.022777253985404967 at epoch 1 \n",
      "train_loss is 0.022345450669527055 at epoch 1 \n",
      "train_loss is 0.017868927866220474 at epoch 1 \n",
      "train_loss is 0.01735518664121628 at epoch 1 \n",
      "train_loss is 0.016861631274223327 at epoch 1 \n",
      "test_loss is 13.504170194268227\n",
      "train_loss is 0.02071248471736908 at epoch 1 \n",
      "train_loss is 0.024772884249687196 at epoch 1 \n",
      "train_loss is 0.015678907483816146 at epoch 1 \n",
      "train_loss is 0.015260659605264664 at epoch 1 \n",
      "train_loss is 0.01484364628791809 at epoch 1 \n",
      "train_loss is 0.023795539587736128 at epoch 1 \n",
      "train_loss is 0.018882188200950622 at epoch 1 \n",
      "train_loss is 0.013879536688327788 at epoch 1 \n",
      "train_loss is 0.0183612023293972 at epoch 1 \n",
      "train_loss is 0.01322403535246849 at epoch 1 \n",
      "test_loss is 12.332410752773285\n",
      "train_loss is 0.012882249057292938 at epoch 1 \n",
      "train_loss is 0.022660882025957108 at epoch 1 \n",
      "train_loss is 0.012322414815425873 at epoch 1 \n",
      "train_loss is 0.012045794054865838 at epoch 1 \n",
      "train_loss is 0.011742283925414085 at epoch 1 \n",
      "train_loss is 0.016740870401263236 at epoch 1 \n",
      "train_loss is 0.02725215122103691 at epoch 1 \n",
      "train_loss is 0.01647517256438732 at epoch 1 \n",
      "train_loss is 0.0163521908223629 at epoch 1 \n",
      "train_loss is 0.010718864798545837 at epoch 1 \n",
      "test_loss is 11.64228643476963\n",
      "train_loss is 0.016016036197543146 at epoch 1 \n",
      "train_loss is 0.010274753496050835 at epoch 1 \n",
      "train_loss is 0.01005136139690876 at epoch 1 \n",
      "train_loss is 0.009814682975411415 at epoch 1 \n",
      "train_loss is 0.01534309983253479 at epoch 1 \n",
      "train_loss is 0.02101018138229847 at epoch 1 \n",
      "train_loss is 0.009317809641361237 at epoch 1 \n",
      "train_loss is 0.009117165505886078 at epoch 1 \n",
      "train_loss is 0.008910738527774811 at epoch 1 \n",
      "train_loss is 0.008713918924331664 at epoch 1 \n",
      "test_loss is 11.189120583236217\n",
      "train_loss is 0.014473480284214019 at epoch 2 \n",
      "train_loss is 0.008238754272460937 at epoch 2 \n",
      "train_loss is 0.008065611273050308 at epoch 2 \n",
      "train_loss is 0.014146543219685554 at epoch 2 \n",
      "train_loss is 0.0077780957520008085 at epoch 2 \n",
      "train_loss is 0.007612653151154518 at epoch 2 \n",
      "train_loss is 0.02026639699935913 at epoch 2 \n",
      "train_loss is 0.007390540018677711 at epoch 2 \n",
      "train_loss is 0.007253724634647369 at epoch 2 \n",
      "train_loss is 0.013656200021505355 at epoch 2 \n",
      "test_loss is 10.936239294707775\n",
      "train_loss is 0.007005617544054985 at epoch 2 \n",
      "train_loss is 0.013506227359175681 at epoch 2 \n",
      "train_loss is 0.006780304238200188 at epoch 2 \n",
      "train_loss is 0.006653093472123146 at epoch 2 \n",
      "train_loss is 0.0065249897539615635 at epoch 2 \n",
      "train_loss is 0.006393475532531738 at epoch 2 \n",
      "train_loss is 0.006270324178040028 at epoch 2 \n",
      "train_loss is 0.006147773787379265 at epoch 2 \n",
      "train_loss is 0.01298805195838213 at epoch 2 \n",
      "train_loss is 0.005960121974349022 at epoch 2 \n",
      "test_loss is 10.831778913736343\n",
      "train_loss is 0.005848727859556675 at epoch 2 \n",
      "train_loss is 0.019901383891701697 at epoch 2 \n",
      "train_loss is 0.012821261025965213 at epoch 2 \n",
      "train_loss is 0.00565393254160881 at epoch 2 \n",
      "train_loss is 0.01273767814040184 at epoch 2 \n",
      "train_loss is 0.005505195334553719 at epoch 2 \n",
      "train_loss is 0.012654731497168541 at epoch 2 \n",
      "train_loss is 0.005356269516050815 at epoch 2 \n",
      "train_loss is 0.012564352974295616 at epoch 2 \n",
      "train_loss is 0.005207029543817044 at epoch 2 \n",
      "test_loss is 10.81879248470068\n",
      "train_loss is 0.00512003693729639 at epoch 2 \n",
      "train_loss is 0.005027999505400658 at epoch 2 \n",
      "train_loss is 0.004941244535148144 at epoch 2 \n",
      "train_loss is 0.004854711331427097 at epoch 2 \n",
      "train_loss is 0.012322311364114285 at epoch 2 \n",
      "train_loss is 0.004728083498775959 at epoch 2 \n",
      "train_loss is 0.0046473203971982005 at epoch 2 \n",
      "train_loss is 0.00456881370395422 at epoch 2 \n",
      "train_loss is 0.004491046741604805 at epoch 2 \n",
      "train_loss is 0.004414640180766582 at epoch 2 \n",
      "test_loss is 10.868240922689438\n",
      "train_loss is 0.004340090081095696 at epoch 2 \n",
      "train_loss is 0.004266973733901978 at epoch 2 \n",
      "train_loss is 0.004192222654819488 at epoch 2 \n",
      "train_loss is 0.004126138836145401 at epoch 2 \n",
      "train_loss is 0.01203558273613453 at epoch 2 \n",
      "train_loss is 0.027970262914896012 at epoch 2 \n",
      "train_loss is 0.004065539687871933 at epoch 2 \n",
      "train_loss is 0.012022888362407684 at epoch 2 \n",
      "train_loss is 0.003998339474201203 at epoch 2 \n",
      "train_loss is 0.011992205232381821 at epoch 2 \n",
      "test_loss is 10.932417146861553\n",
      "train_loss is 0.003912981450557709 at epoch 2 \n",
      "train_loss is 0.0200502023473382 at epoch 2 \n",
      "train_loss is 0.0200310268253088 at epoch 2 \n",
      "train_loss is 0.003879571780562401 at epoch 2 \n",
      "train_loss is 0.0038298584520816805 at epoch 2 \n",
      "train_loss is 0.011929092407226562 at epoch 2 \n",
      "train_loss is 0.003739800974726677 at epoch 2 \n",
      "train_loss is 0.011901185438036919 at epoch 2 \n",
      "train_loss is 0.003661593310534954 at epoch 2 \n",
      "train_loss is 0.011882888674736023 at epoch 2 \n",
      "test_loss is 11.001985117793083\n",
      "train_loss is 0.011872514970600606 at epoch 2 \n",
      "train_loss is 0.0035722778365015985 at epoch 2 \n",
      "train_loss is 0.0035256870090961457 at epoch 2 \n",
      "train_loss is 0.0034715360775589943 at epoch 2 \n",
      "train_loss is 0.0118370059132576 at epoch 2 \n",
      "train_loss is 0.003398183174431324 at epoch 2 \n",
      "train_loss is 0.0033547213301062585 at epoch 2 \n",
      "train_loss is 0.0033031580597162246 at epoch 2 \n",
      "train_loss is 0.0032534625753760336 at epoch 2 \n",
      "train_loss is 0.0032046157121658325 at epoch 2 \n",
      "test_loss is 11.131831299513578\n",
      "train_loss is 0.003139666747301817 at epoch 3 \n",
      "train_loss is 0.0031066340394318103 at epoch 3 \n",
      "train_loss is 0.020460602585226296 at epoch 3 \n",
      "train_loss is 0.011753812786191703 at epoch 3 \n",
      "train_loss is 0.011760976072400809 at epoch 3 \n",
      "train_loss is 0.003062539901584387 at epoch 3 \n",
      "train_loss is 0.011737955845892429 at epoch 3 \n",
      "train_loss is 0.0030105360969901085 at epoch 3 \n",
      "train_loss is 0.0029740935377776624 at epoch 3 \n",
      "train_loss is 0.0029305196553468704 at epoch 3 \n",
      "test_loss is 11.236174138262868\n",
      "train_loss is 0.0028821779787540436 at epoch 3 \n",
      "train_loss is 0.0028469774685800074 at epoch 3 \n",
      "train_loss is 0.011730792112648486 at epoch 3 \n",
      "train_loss is 0.011732302196323872 at epoch 3 \n",
      "train_loss is 0.002781775426119566 at epoch 3 \n",
      "train_loss is 0.0027606329508125783 at epoch 3 \n",
      "train_loss is 0.00271904855966568 at epoch 3 \n",
      "train_loss is 0.00268023207783699 at epoch 3 \n",
      "train_loss is 0.002642172370105982 at epoch 3 \n",
      "train_loss is 0.0026076001301407812 at epoch 3 \n",
      "test_loss is 11.394219234585762\n",
      "train_loss is 0.002567461933940649 at epoch 3 \n",
      "train_loss is 0.0025334557704627513 at epoch 3 \n",
      "train_loss is 0.002500535324215889 at epoch 3 \n",
      "train_loss is 0.011720206588506699 at epoch 3 \n",
      "train_loss is 0.0024592377804219722 at epoch 3 \n",
      "train_loss is 0.002431807927787304 at epoch 3 \n",
      "train_loss is 0.0023956229351460934 at epoch 3 \n",
      "train_loss is 0.011710874829441309 at epoch 3 \n",
      "train_loss is 0.00236016808077693 at epoch 3 \n",
      "train_loss is 0.0023368206061422825 at epoch 3 \n",
      "test_loss is 11.556679368019104\n",
      "train_loss is 0.02110223302617669 at epoch 3 \n",
      "train_loss is 0.011702224984765053 at epoch 3 \n",
      "train_loss is 0.002331003379076719 at epoch 3 \n",
      "train_loss is 0.0023132330365478993 at epoch 3 \n",
      "train_loss is 0.0022814615815877916 at epoch 3 \n",
      "train_loss is 0.0022514613531529905 at epoch 3 \n",
      "train_loss is 0.002223378233611584 at epoch 3 \n",
      "train_loss is 0.011719333212822676 at epoch 3 \n",
      "train_loss is 0.002192223519086838 at epoch 3 \n",
      "train_loss is 0.01175225542858243 at epoch 3 \n",
      "test_loss is 11.663129637017846\n",
      "train_loss is 0.011739432308822871 at epoch 3 \n",
      "train_loss is 0.002176806665956974 at epoch 3 \n",
      "train_loss is 0.0021500271558761597 at epoch 3 \n",
      "train_loss is 0.011752199083566665 at epoch 3 \n",
      "train_loss is 0.0021252221427857875 at epoch 3 \n",
      "train_loss is 0.0021006667241454126 at epoch 3 \n",
      "train_loss is 0.0020709191262722015 at epoch 3 \n",
      "train_loss is 0.01176915930584073 at epoch 3 \n",
      "train_loss is 0.011760692019015551 at epoch 3 \n",
      "train_loss is 0.011777137052267789 at epoch 3 \n",
      "test_loss is 11.74416291154921\n",
      "train_loss is 0.011773285362869501 at epoch 3 \n",
      "train_loss is 0.002067050635814667 at epoch 3 \n",
      "train_loss is 0.002044812496751547 at epoch 3 \n",
      "train_loss is 0.002018931917846203 at epoch 3 \n",
      "train_loss is 0.031285755299031735 at epoch 3 \n",
      "train_loss is 0.0020578137785196306 at epoch 3 \n",
      "train_loss is 0.011745121348649263 at epoch 3 \n",
      "train_loss is 0.011745195835828781 at epoch 3 \n",
      "train_loss is 0.0020449663512408733 at epoch 3 \n",
      "train_loss is 0.011763245444744825 at epoch 3 \n",
      "test_loss is 12.109251145273447\n",
      "train_loss is 0.021503629442304373 at epoch 3 \n",
      "train_loss is 0.0020596231147646904 at epoch 3 \n",
      "train_loss is 0.0020395144447684288 at epoch 3 \n",
      "train_loss is 0.011744463611394166 at epoch 3 \n",
      "train_loss is 0.0020200736075639725 at epoch 3 \n",
      "train_loss is 0.0019969579949975012 at epoch 3 \n",
      "train_loss is 0.0019720211066305638 at epoch 3 \n",
      "train_loss is 0.0019509525410830975 at epoch 3 \n",
      "train_loss is 0.0019248419255018235 at epoch 3 \n",
      "train_loss is 0.0019016608223319054 at epoch 3 \n",
      "test_loss is 11.900861261412501\n"
     ]
    }
   ],
   "source": [
    "net = ECGNet()\n",
    "train_test_net(net,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9815, 0.0185],\n",
      "        [0.9814, 0.0186],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9815, 0.0185],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9811, 0.0189]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9818, 0.0182],\n",
      "        [0.9816, 0.0184],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9815, 0.0185],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9815, 0.0185],\n",
      "        [0.9814, 0.0186]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9815, 0.0185],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9811, 0.0189],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9815, 0.0185],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9814, 0.0186]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9814, 0.0186],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "tensor([[0.9816, 0.0184],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9814, 0.0186]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9816, 0.0184],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9811, 0.0189]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9814, 0.0186],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9811, 0.0189],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9814, 0.0186]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9811, 0.0189]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9816, 0.0184],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9815, 0.0185],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9811, 0.0189]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9815, 0.0185],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9816, 0.0184],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9814, 0.0186],\n",
      "        [0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9811, 0.0189]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9815, 0.0185],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9814, 0.0186],\n",
      "        [0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9814, 0.0186]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9811, 0.0189]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9813, 0.0187],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9813, 0.0187],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9814, 0.0186],\n",
      "        [0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9813, 0.0187]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.9814, 0.0186],\n",
      "        [0.9812, 0.0188],\n",
      "        [0.9812, 0.0188]], grad_fn=<SoftmaxBackward0>) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for data,label in test_loader:\n",
    "    output = net(data)\n",
    "    print(output,label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}